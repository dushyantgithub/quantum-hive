# ğŸ§  Quantum Hive

**Quantum Hive** is an offline-capable, Jarvis-like AI assistant built on a Raspberry Pi 4 (8GB). It uses local speech-to-text and text-to-speech systems, processes natural language using either local or API-based LLMs, and responds with a speaking avatar UI.

---

## ğŸš€ Features

- ğŸ¤ Offline speech-to-text using Vosk
- ğŸ’¬ AI response from either OpenAI (cloud) or quantized LLM (local)
- ğŸ—£ï¸ Voice responses using eSpeak NG or Coqui TTS
- ğŸ‘ï¸ Face-tracking avatar UI built with Electron + Three.js (in progress)
- ğŸŒ Raspberry Pi acts as an edge server, remotely accessible
- ğŸ”Œ Google Home integration planned for device control

---

## ğŸ“ Project Structure Created

Here's what we've set up for you:

```
quantum-hive/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                # âœ… Core app logic (STT â†’ AI â†’ TTS loop)
â”‚   â”œâ”€â”€ stt/                   # âœ… Speech-to-text (Vosk)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ vosk_engine.py
â”‚   â”œâ”€â”€ tts/                   # âœ… Text-to-speech (eSpeak/Coqui/pyttsx3)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ tts_engine.py
â”‚   â”œâ”€â”€ ai/                    # âœ… AI logic (local LLM + fallback)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ local_llm.py
â”‚   â””â”€â”€ utils/                 # âœ… Configs, helper tools
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ config.py
â”œâ”€â”€ ui/                        # ğŸ“ Placeholder for future Electron app
â”‚   â””â”€â”€ electron-app/
â”œâ”€â”€ deploy/                    # âœ… Scripts for Pi setup
â”‚   â””â”€â”€ setup_pi.sh
â”œâ”€â”€ tests/                     # âœ… Unit tests
â”‚   â””â”€â”€ test_stt.py
â”œâ”€â”€ README.md                  # âœ… Updated documentation
â”œâ”€â”€ requirements.txt           # âœ… Python dependencies
â”œâ”€â”€ .gitignore                # âœ… Git ignore rules
â””â”€â”€ start_dev.py              # âœ… Development startup script
```

## ğŸš€ Key Features Implemented

### **Speech-to-Text (STT)**

- âœ… Vosk engine with offline speech recognition
- âœ… Microphone input handling
- âœ… Silence detection
- âœ… Audio file transcription

### **Text-to-Speech (TTS)**

- âœ… Multiple engine support (eSpeak, Coqui, pyttsx3)
- âœ… Audio file generation and playback
- âœ… Cross-platform audio support

### **AI Processing**

- âœ… Local LLM with llama.cpp integration
- âœ… Simple fallback AI for when models aren't available
- âœ… Configurable system prompts
- âœ… Conversation history support

### **Configuration & Utilities**

- âœ… Centralized configuration management
- âœ… Logging setup
- âœ… Path management
- âœ… Error handling

### **Deployment**

- âœ… Raspberry Pi setup script
- âœ… Systemd service creation
- âœ… Audio configuration
- âœ… Performance optimizations

## ğŸ§ª Next Steps

1. **Test the setup locally:**

   ```bash
   # Install dependencies
   pip install -r requirements.txt

   # Test individual components
   python backend/stt/vosk_engine.py
   python backend/tts/tts_engine.py
   python backend/ai/local_llm.py

   # Run the full application
   python start_dev.py
   ```

2. **Download Vosk model:**

   ```bash
   mkdir models
   cd models
   wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
   unzip vosk-model-small-en-us-0.15.zip
   ```

3. **For Raspberry Pi deployment:**
   ```bash
   chmod +x deploy/setup_pi.sh
   ./deploy/setup_pi.sh
   ```

## ğŸ”§ Quick Start

````bash
# Clone the repo
git clone https://github.com/your-username/quantum-hive.git
cd quantum-hive

# Create a Python virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the assistant
python backend/main.py
ğŸ“¦ Future Add-ons

Local LLM with llama.cpp or ggml
MQTT/HTTP device control via Google Home
Avatar with gesture animation & lip-sync
Web dashboard for remote access
ğŸ›  Contributors

ğŸ§  You (the human behind the AI)
ğŸ¤– ChatGPT (your assistant for building it)
ğŸ“œ License

MIT License


---

### âœ… Next Steps

1. Do you want me to generate this folder with template `.py` files and a working `main.py` that ties STT â†’ AI â†’ TTS?
2. Would you like to start with **Vosk + eSpeak** for first testing?

Let me know if you'd like this as a downloadable ZIP or GitHub-ready format.

ğŸ‰ **AMAZING! Your Quantum Hive is working perfectly!**

## ğŸ§ª Test Results Summary

âœ… **All components are working:**

1. **Speech-to-Text (STT)**: âœ… Vosk engine successfully transcribed your speech
2. **Text-to-Speech (TTS)**: âœ… pyttsx3 engine spoke the responses clearly
3. **AI Processing**: âœ… Simple AI engine provided responses
4. **Full Integration**: âœ… Complete STT â†’ AI â†’ TTS workflow working

## ğŸ¤” What Just Happened

The system successfully:
- **Listened** to your speech using Vosk STT
- **Processed** your input through the AI engine
- **Spoke back** responses using pyttsx3 TTS
- **Detected exit commands** and shut down gracefully

## ğŸ”§ Current Configuration

- **STT**: Vosk with offline English model
- **TTS**: pyttsx3 (macOS native speech synthesis)
- **AI**: Simple rule-based engine (fallback mode)
- **Audio**: Real-time microphone input and speaker output

## ğŸš€ Next Steps for Enhancement

1. **Improve AI Responses**: Install llama-cpp-python for better AI
   ```bash
   pip install llama-cpp-python
````

2. **Add More Commands**: Extend the SimpleAIEngine with more responses

3. **Test on Raspberry Pi**: Use the deployment script we created

4. **Add Voice Commands**: Implement specific voice commands for device control

## ğŸ‰ Congratulations!

Your Quantum Hive AI assistant is now fully functional! You can:

- Speak to it and get voice responses
- Have basic conversations
- Use voice commands to exit ("goodbye", "exit", etc.)

The system is ready for further development and can be deployed to your Raspberry Pi when you're ready! ğŸš€

```

```

